"""
ChatGoogleGenerativeAI ìƒì„¸ í…ŒìŠ¤íŠ¸
ëª©ì : ì¸ì ë° ë°˜í™˜ê°’ ìƒì„¸ ë¶„ì„
"""

import os
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from common.logger import log_info, log_debug

def test_detailed_usage():
    """ìƒì„¸ ì‚¬ìš©ë²• í…ŒìŠ¤íŠ¸"""
    
    load_dotenv()
    api_key = os.getenv('GEMINI_API_KEY')
    
    # ë‹¤ì–‘í•œ ì¸ìë¡œ ì´ˆê¸°í™”
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash-exp",
        google_api_key=api_key,
        temperature=0.1,                    # ë‚®ì€ ì°½ì˜ì„±
        max_output_tokens=100,              # ìµœëŒ€ 100í† í°
        top_p=0.8,                         # ìƒìœ„ 80% í™•ë¥  í† í°ë§Œ
        stop=[".", "!"],                   # ë§ˆì¹¨í‘œë‚˜ ê°íƒ„í‘œì—ì„œ ì¤‘ë‹¨
        verbose=True                       # ìƒì„¸ ë¡œê·¸
    )
    
    # í˜¸ì¶œ ë° ê²°ê³¼ ë¶„ì„
    result = llm.invoke("ë³‘ë¦¬ë³´ê³ ì„œë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”")
    
    log_info(f"ì‘ë‹µ ë‚´ìš©: {result.content}")
    log_debug(f"ì‘ë‹µ íƒ€ì…: {type(result)}")
    log_debug(f"ë©”íƒ€ë°ì´í„°: {result.response_metadata}")
    
    # ì†ì„± ì ‘ê·¼
    print(f"ğŸ“ ìƒì„±ëœ í…ìŠ¤íŠ¸: {result.content}")
    print(f"ğŸ”§ ì‚¬ìš©ëœ ëª¨ë¸: {result.response_metadata.get('model_name', 'N/A')}")
    print(f"ğŸ“Š í† í° ì‚¬ìš©ëŸ‰: {getattr(result, 'usage_metadata', {})}")
    
    return result

if __name__ == "__main__":
    test_detailed_usage()